{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n\\nThere are 8 planets in the solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.',\n",
       " 'There are 8 planets in the solar system: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-1 LLM and Chat Models\n",
    "from langchain_openai import OpenAI, ChatOpenAI # LLM, Chat model\n",
    "\n",
    "llm = OpenAI()\n",
    "chat = ChatOpenAI()\n",
    "\n",
    "a = llm.predict(\"How many planets are in the solar system?\")\n",
    "b = chat.predict(\"How many planets are in the solar system?\")\n",
    "\n",
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri. Come posso aiutarti oggi?', response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 53, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-5d70edf0-b4f7-4009-b92d-67c8026a8622-0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2-2. Predict Messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "# HumanMessage - 인간이 작성하는 Message\n",
    "# AIMessage - AI에 의해서 보내지는 Message\n",
    "# SystemMessage - LLM에 설정들을 제공하기 위한 Message\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a geography expert. And you only reply in Italian.\"),\n",
    "    AIMessage(content=\"Ciao, mi chiamo Paolo!\"),\n",
    "    HumanMessage(content=\"What is the distance between the Mexico and Thailand. Also, what is your name?\"),\n",
    "]\n",
    "\n",
    "chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Ciao! La distanza tra il Messico e la Thailandia è di circa 16.000 chilometri. Come posso aiutarti oggi?', response_metadata={'token_usage': {'completion_tokens': 34, 'prompt_tokens': 53, 'total_tokens': 87}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-dfa458b7-47b5-4a38-bb5c-5915b03889c9-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 2-3. Prompt Templates\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    ")\n",
    "\n",
    "# 일반 문자열 출력 예제\n",
    "# template = PromptTemplate.from_template(\"What is the distance between {country_a} and {country_b}\")\n",
    "# prompt = template.format(country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "# chat.predict(prompt)\n",
    "\n",
    "# 메시지 출력 예제\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a geography expert. And you only reply in {language}.\"),\n",
    "    AIMessagePromptTemplate.from_template(\"Ciao, mi chiamo {name}!\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"What is the distance between the {country_a} and {country_b}. Also, what is your name?\")\n",
    "]\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = template.format_messages(language=\"Italian\", name=\"Paolo\", country_a=\"Mexico\", country_b=\"Thailand\")\n",
    "\n",
    "chat.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red',\n",
       " 'blue',\n",
       " 'green',\n",
       " 'yellow',\n",
       " 'orange',\n",
       " 'purple',\n",
       " 'pink',\n",
       " 'black',\n",
       " 'white',\n",
       " 'brown']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-4. OutputParser and LCEL\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import BaseOutputParser\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    ")\n",
    "\n",
    "# 문자열 출력을 파싱하는 BaseOutputParser 확장하는 커스텀 OutputParser\n",
    "class CommaOutputParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> str:\n",
    "        items = text.strip().split(\",\")\n",
    "        return list(map(str.strip, items))\n",
    "    \n",
    "\n",
    "# OutputParser 예제 (LCEL 적용 전)\n",
    "# p = CommaOutputParser()\n",
    "# messages = [\n",
    "#     SystemMessagePromptTemplate.from_template(\"You are a list gernerating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do Not reply with else.\"),\n",
    "#     HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "# ]\n",
    "# template = ChatPromptTemplate.from_messages(messages)\n",
    "# prompt = template.format_messages(max_items=10, question=\"What are the colors?\")\n",
    "# res = chat.invoke(prompt)\n",
    "# p.parse(res.content)\n",
    "\n",
    "# OutputParser 예제 (LCEL 적용 후)\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a list gernerating machine. Everything you are asked will be answered with a comma separated list of max {max_items} in lowercase. Do Not reply with else.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "template = ChatPromptTemplate.from_messages(messages)\n",
    "chain = template | chat | CommaOutputParser()\n",
    "chain.invoke({\n",
    "    \"max_items\":10, \n",
    "    \"question\":\"What are the colors?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Great choice! Indian cuisine is known for its bold flavors and aromatic spices. Here's a simple recipe for Chicken Tikka Masala, a popular Indian dish that you can easily make at home.\n",
      "\n",
      "Chicken Tikka Masala\n",
      "\n",
      "Ingredients:\n",
      "- 1 lb boneless, skinless chicken breasts, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt\n",
      "- 2 tbsp lemon juice\n",
      "- 2 tbsp vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 can (14 oz) diced tomatoes\n",
      "- 2 tbsp tomato paste\n",
      "- 1 tbsp garam masala\n",
      "- 1 tsp ground cumin\n",
      "- 1 tsp ground coriander\n",
      "- 1/2 tsp turmeric\n",
      "- 1/2 tsp paprika\n",
      "- 1/2 tsp cayenne pepper (adjust to taste)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "Instructions:\n",
      "1. In a bowl, combine the yogurt, lemon juice, 1 tbsp vegetable oil, half of the minced garlic, half of the grated ginger, 1 tbsp garam masala, 1/2 tsp cumin, 1/2 tsp coriander, turmeric, paprika, cayenne pepper, salt, and pepper. Add the chicken pieces and mix well to coat. Cover and marinate in the refrigerator for at least 1 hour, or overnight for best results.\n",
      "\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated chicken onto skewers and place them on a baking sheet lined with foil. Bake for 20-25 minutes or until the chicken is cooked through.\n",
      "\n",
      "3. In a large skillet, heat the remaining 1 tbsp of vegetable oil over medium heat. Add the chopped onion and cook until softened, about 5 minutes. Add the remaining garlic and ginger, and cook for another minute.\n",
      "\n",
      "4. Stir in the diced tomatoes, tomato paste, 1 tbsp garam masala, 1/2 tsp cumin, and 1/2 tsp coriander. Simmer for 10-15 minutes, stirring occasionally, until the sauce thickens.\n",
      "\n",
      "5. Add the cooked chicken tikka to the sauce and simmer for an additional 5 minutes to allow the flavors to meld together. Adjust seasoning with salt, pepper, and cayenne pepper if needed.\n",
      "\n",
      "6. Serve the Chicken Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro before serving.\n",
      "\n",
      "Enjoy your homemade Chicken Tikka Masala with its rich and flavorful sauce!To make this Chicken Tikka Masala recipe vegetarian, we can replace the chicken with a suitable alternative such as paneer or tofu. Here's how you can adapt the recipe:\n",
      "\n",
      "**Vegetarian Chicken Tikka Masala**\n",
      "\n",
      "**Ingredients:**\n",
      "- 1 lb paneer or extra-firm tofu, cut into bite-sized pieces\n",
      "- 1 cup plain yogurt (you can use plant-based yogurt for a vegan version)\n",
      "- 2 tbsp lemon juice\n",
      "- 2 tbsp vegetable oil\n",
      "- 1 onion, finely chopped\n",
      "- 3 cloves garlic, minced\n",
      "- 1-inch piece of ginger, grated\n",
      "- 1 can (14 oz) diced tomatoes\n",
      "- 2 tbsp tomato paste\n",
      "- 1 tbsp garam masala\n",
      "- 1 tsp ground cumin\n",
      "- 1 tsp ground coriander\n",
      "- 1/2 tsp turmeric\n",
      "- 1/2 tsp paprika\n",
      "- 1/2 tsp cayenne pepper (adjust to taste)\n",
      "- Salt and pepper to taste\n",
      "- Fresh cilantro, chopped (for garnish)\n",
      "- Cooked rice or naan bread (for serving)\n",
      "\n",
      "**Instructions:**\n",
      "1. Follow the same marination process as in the original recipe, but instead of chicken, marinate the paneer or tofu in the yogurt and spice mixture. Let it marinate for at least 1 hour in the refrigerator.\n",
      "\n",
      "2. Preheat the oven to 400°F (200°C). Thread the marinated paneer or tofu onto skewers and bake for 20-25 minutes or until lightly browned.\n",
      "\n",
      "3. In a large skillet, follow the same steps for sautéing the onion, garlic, and ginger. Add the diced tomatoes, tomato paste, and spices. Simmer the sauce until it thickens.\n",
      "\n",
      "4. Add the baked paneer or tofu to the sauce and simmer for an additional 5 minutes to allow the flavors to blend.\n",
      "\n",
      "5. Adjust the seasoning with salt, pepper, and cayenne pepper if needed.\n",
      "\n",
      "6. Serve the Vegetarian Chicken Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro before serving.\n",
      "\n",
      "By making these simple swaps, you can enjoy a delicious and vegetarian-friendly version of Chicken Tikka Masala that retains the authentic flavors of the dish. Enjoy your meal!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"To make this Chicken Tikka Masala recipe vegetarian, we can replace the chicken with a suitable alternative such as paneer or tofu. Here's how you can adapt the recipe:\\n\\n**Vegetarian Chicken Tikka Masala**\\n\\n**Ingredients:**\\n- 1 lb paneer or extra-firm tofu, cut into bite-sized pieces\\n- 1 cup plain yogurt (you can use plant-based yogurt for a vegan version)\\n- 2 tbsp lemon juice\\n- 2 tbsp vegetable oil\\n- 1 onion, finely chopped\\n- 3 cloves garlic, minced\\n- 1-inch piece of ginger, grated\\n- 1 can (14 oz) diced tomatoes\\n- 2 tbsp tomato paste\\n- 1 tbsp garam masala\\n- 1 tsp ground cumin\\n- 1 tsp ground coriander\\n- 1/2 tsp turmeric\\n- 1/2 tsp paprika\\n- 1/2 tsp cayenne pepper (adjust to taste)\\n- Salt and pepper to taste\\n- Fresh cilantro, chopped (for garnish)\\n- Cooked rice or naan bread (for serving)\\n\\n**Instructions:**\\n1. Follow the same marination process as in the original recipe, but instead of chicken, marinate the paneer or tofu in the yogurt and spice mixture. Let it marinate for at least 1 hour in the refrigerator.\\n\\n2. Preheat the oven to 400°F (200°C). Thread the marinated paneer or tofu onto skewers and bake for 20-25 minutes or until lightly browned.\\n\\n3. In a large skillet, follow the same steps for sautéing the onion, garlic, and ginger. Add the diced tomatoes, tomato paste, and spices. Simmer the sauce until it thickens.\\n\\n4. Add the baked paneer or tofu to the sauce and simmer for an additional 5 minutes to allow the flavors to blend.\\n\\n5. Adjust the seasoning with salt, pepper, and cayenne pepper if needed.\\n\\n6. Serve the Vegetarian Chicken Tikka Masala over cooked rice or with naan bread. Garnish with chopped cilantro before serving.\\n\\nBy making these simple swaps, you can enjoy a delicious and vegetarian-friendly version of Chicken Tikka Masala that retains the authentic flavors of the dish. Enjoy your meal!\", response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-ff5c6b6a-ea03-4d52-906e-24b6d2167bf8-0')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-5. Chaining Chains\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    "    streaming=True, # streaming 옵션을 활성화하여 대화형 모드로 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()], # 콜백 함수를 설정\n",
    ")\n",
    "\n",
    "chef_message =  [\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a world-class international chef. You create easy to fllow recipies for any type of cuisine with easy to find ingredients.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"I want to cook {cuisine} food.\")\n",
    "]\n",
    "\n",
    "chef_prompt = ChatPromptTemplate.from_messages(chef_message)\n",
    "\n",
    "chef_chain = chef_prompt | chat\n",
    "\n",
    "veg_chef_message =  [\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a vegetarian chef specialized on marking tranditional recipies vegetarian. You find alternatibe ingredients and explain their preparation. You don't redically modify the recipe. If there is no alternative for a food just say you don't know how to replace it.\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{recipe}\")\n",
    "]\n",
    "\n",
    "veg_chef_prompt = ChatPromptTemplate.from_messages(veg_chef_message)\n",
    "\n",
    "veg_chef_chain = veg_chef_prompt | chat\n",
    "\n",
    "# RunnableMap 사용\n",
    "final_chain = {\"recipe\": chef_chain} | veg_chef_chain\n",
    "\n",
    "final_chain.invoke({\n",
    "    \"cuisine\":\"indian\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: \n",
      "        Here is what I know:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='AI: \\n        Here is what I know:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-ad352a6e-fc3a-4551-95b2-9c12e1047740-0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-1. FewShotPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    "    streaming=True, # streaming 옵션을 활성화하여 대화형 모드로 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()], # 콜백 함수를 설정\n",
    ")\n",
    "\n",
    "# 모델에게 전달하는 답변 예제\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    }]\n",
    "\n",
    "\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt, # Prompt 방식\n",
    "    examples=examples, # 답변 예제\n",
    "    suffix=\"Human: Wat do you know about {country}?\", # 모든 형식화된 예제 마지막 내용\n",
    "    input_variables=[\"country\"] # suffix 입력 변수 (유효성 검사)\n",
    ")\n",
    "\n",
    "chain = prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\":\"Germ\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        I know this:\n",
      "        Capital: Berlin\n",
      "        Language: German\n",
      "        Food: Bratwurst and Sauerkraut\n",
      "        Currency: Euro"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='\\n        I know this:\\n        Capital: Berlin\\n        Language: German\\n        Food: Bratwurst and Sauerkraut\\n        Currency: Euro', response_metadata={'finish_reason': 'stop', 'model_name': 'gpt-3.5-turbo-0125'}, id='run-7b9ef8ec-ad1b-401c-b57e-66167b93f3ad-0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-2. FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import PromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    "    streaming=True, # streaming 옵션을 활성화하여 대화형 모드로 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()], # 콜백 함수를 설정\n",
    ")\n",
    "\n",
    "# 모델에게 전달하는 답변 예제\n",
    "examples = [\n",
    "    {\n",
    "        \"country\": \"France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"country\": \"Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    }]\n",
    "\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"What do you know about {country}?\"),\n",
    "    AIMessagePromptTemplate.from_template(\"{answer}\"),\n",
    "]\n",
    ")\n",
    "\n",
    "prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt, # Prompt 방식\n",
    "    examples=examples, # 답변 예제\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(\"You are a geography expert, you give short answers\"),\n",
    "    prompt,\n",
    "    HumanMessagePromptTemplate.from_template(\"What do you know about {country}?\")\n",
    "])\n",
    "\n",
    "chain = final_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"country\":\"Germany\",\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Human: What do you know about Greece?\\nAI: \\n        I know this:\\n        Capital: Athens\\n        Language: Greek\\n        Food: Souvlaki and Feta Cheese\\n        Currency: Euro\\n        \\n\\nHuman: Wat do you know about Brazil?'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-3. LengthBasedExampleSelector\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import PromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.prompts.example_selector.base import BaseExampleSelector\n",
    "\n",
    "class RandomExampleSelector(BaseExampleSelector):\n",
    "    def __init__(self, examples):\n",
    "        self.examples = examples\n",
    "    \n",
    "    def add_example(self, example):\n",
    "        self.examples.append(example)\n",
    "\n",
    "    def select_examples(self, input_variables):\n",
    "        from random import choice\n",
    "        return [choice(self.examples)]\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    "    streaming=True, # streaming 옵션을 활성화하여 대화형 모드로 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()], # 콜백 함수를 설정\n",
    ")\n",
    "\n",
    "# 모델에게 전달하는 답변 예제\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"What do you know about France?\",\n",
    "        \"answer\": \"\"\"\n",
    "        Here is what I know:\n",
    "        Capital: Paris\n",
    "        Language: French\n",
    "        Food: Wine and Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Italy?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Rome\n",
    "        Language: Italian\n",
    "        Food: Pizza and Pasta\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"What do you know about Greece?\",\n",
    "        \"answer\": \"\"\"\n",
    "        I know this:\n",
    "        Capital: Athens\n",
    "        Language: Greek\n",
    "        Food: Souvlaki and Feta Cheese\n",
    "        Currency: Euro\n",
    "        \"\"\",\n",
    "    }]\n",
    "\n",
    "example_prompt = PromptTemplate.from_template(\"Human: {question}\\nAI: {answer}\")\n",
    "\n",
    "# 예제 선택\n",
    "example_selector = RandomExampleSelector(\n",
    "    examples=examples, # 답변 예제\n",
    ")\n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    example_prompt=example_prompt, # Prompt 방식\n",
    "    example_selector=example_selector, # 답변 선택\n",
    "    suffix=\"Human: Wat do you know about {country}?\", # 모든 형식화된 예제 마지막 내용\n",
    "    input_variables=[\"country\"] # suffix 입력 변수 (유효성 검사)\n",
    ")\n",
    "\n",
    "prompt.format(country=\"Brazil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    \\n    You are a role playing assistant.\\n    And you are impersonating a Pirate\\n\\n                                     \\n    \\n    This is an example of how you talk:\\n\\n    Human: What is your location?\\n    You: Arrrrg! That is a secret!! Arg arg!!\\n\\n                              \\n    \\n    Start now!\\n\\n    Human: What is your fav food?\\n    You:\\n\\n'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-4. Serialization and Composition\n",
    "from langchain_openai import ChatOpenAI\n",
    "# PromptTemplate - 문자열을 이용한 template 생성\n",
    "# ChatPromptTemplate - message를 이용하여 template 생성\n",
    "from langchain.prompts import PromptTemplate, ChatMessagePromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain.callbacks import StreamingStdOutCallbackHandler\n",
    "# Prompt 파일 불러오기\n",
    "# from langchain.prompts import load_prompt\n",
    "# Prompt Pipeline 불러오기\n",
    "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
    "\n",
    "# Prompt 파일 불러오기\n",
    "# prompt = load_prompt(\"./prompt.json\")\n",
    "# prompt = load_prompt(\"./prompt.yaml\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    temperature=0.1, # 모델의 창의성을 조절하는 옵션 (높을 수록 창의적임)\n",
    "    streaming=True, # streaming 옵션을 활성화하여 대화형 모드로 설정\n",
    "    callbacks=[StreamingStdOutCallbackHandler()], # 콜백 함수를 설정\n",
    ")\n",
    "\n",
    "# Prompt 파일 불러오기\n",
    "# prompt.format(country=\"Germany\")\n",
    "\n",
    "intro = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are a role playing assistant.\n",
    "    And you are impersonating a {character}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "example = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    This is an example of how you talk:\n",
    "\n",
    "    Human: {example_question}\n",
    "    You: {example_answer}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "start = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Start now!\n",
    "\n",
    "    Human: {question}\n",
    "    You:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "final = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    {intro}\n",
    "                                     \n",
    "    {example}\n",
    "                              \n",
    "    {start}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompts = [\n",
    "    (\"intro\", intro),\n",
    "    (\"example\", example),\n",
    "    (\"start\", start),\n",
    "]\n",
    "\n",
    "full_prompt = PipelinePromptTemplate(\n",
    "    final_prompt=final,\n",
    "    pipeline_prompts=prompts,\n",
    ")\n",
    "\n",
    "# full_prompt.format(character=\"Pirate\", example_question=\"What is your location?\", example_answer=\"Arrrrg! That is a secret!! Arg arg!!\", question=\"What is your fav food?\")\n",
    "\n",
    "chain = full_prompt | chat\n",
    "\n",
    "chain.invoke({\n",
    "    \"character\":\"Pirate\",\n",
    "    \"example_question\":\"What is your location?\",\n",
    "    \"example_answer\":\"Arrrrg! That is a secret!! Arg arg\",\n",
    "    \"question\": \"What is your fav food?\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-5. Caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-6. Serialization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
